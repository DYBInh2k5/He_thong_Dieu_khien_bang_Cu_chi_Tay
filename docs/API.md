# üìö API Documentation

## GestureDetector

Class ch√≠nh ƒë·ªÉ nh·∫≠n di·ªán c·ª≠ ch·ªâ tay.

### Constructor
```python
detector = GestureDetector()
```

### Methods

#### `process_frame(frame)`
X·ª≠ l√Ω frame t·ª´ camera v√† tr·∫£ v·ªÅ frame ƒë√£ ƒë∆∞·ª£c v·∫Ω c√πng c·ª≠ ch·ªâ nh·∫≠n di·ªán.

**Parameters:**
- `frame` (numpy.ndarray): Frame t·ª´ camera

**Returns:**
- `tuple`: (frame_processed, gesture_name)
  - `frame_processed`: Frame ƒë√£ v·∫Ω contours v√† th√¥ng tin
  - `gesture_name`: T√™n c·ª≠ ch·ªâ ("zero", "one", "two", ...) ho·∫∑c None

**Example:**
```python
cap = cv2.VideoCapture(0)
detector = GestureDetector()

ret, frame = cap.read()
frame, gesture = detector.process_frame(frame)
print(f"Detected: {gesture}")
```

#### `detect_skin(frame)`
Ph√°t hi·ªán v√πng da trong frame.

**Parameters:**
- `frame` (numpy.ndarray): Frame ƒë·∫ßu v√†o

**Returns:**
- `numpy.ndarray`: Binary mask c·ªßa v√πng da

#### `count_fingers_simple(contour)`
ƒê·∫øm s·ªë ng√≥n tay d·ª±a tr√™n convex hull.

**Parameters:**
- `contour` (numpy.ndarray): Contour c·ªßa b√†n tay

**Returns:**
- `int`: S·ªë ng√≥n tay (0-5)

#### `detect_gesture(finger_count, contour)`
Chuy·ªÉn ƒë·ªïi s·ªë ng√≥n tay th√†nh t√™n c·ª≠ ch·ªâ.

**Parameters:**
- `finger_count` (int): S·ªë ng√≥n tay
- `contour` (numpy.ndarray): Contour c·ªßa b√†n tay

**Returns:**
- `str`: T√™n c·ª≠ ch·ªâ

---

## Controllers

### KeyboardController

ƒêi·ªÅu khi·ªÉn b√†n ph√≠m b·∫±ng c·ª≠ ch·ªâ.

```python
controller = KeyboardController()
controller.execute("one")  # Nh·∫•n ph√≠m "1"
```

#### `execute(gesture)`
**Parameters:**
- `gesture` (str): T√™n c·ª≠ ch·ªâ

**Returns:**
- `str`: Th√¥ng b√°o k·∫øt qu·∫£ ho·∫∑c None

---

### RobotController

ƒêi·ªÅu khi·ªÉn robot b·∫±ng c·ª≠ ch·ªâ.

```python
controller = RobotController()
controller.execute("forward")  # Robot ti·∫øn
```

**Attributes:**
- `position` (list): V·ªã tr√≠ hi·ªán t·∫°i [x, y]
- `direction` (int): H∆∞·ªõng hi·ªán t·∫°i (0-360)

#### `execute(gesture)`
**Parameters:**
- `gesture` (str): T√™n c·ª≠ ch·ªâ ("forward", "left", "right", "backward", "stop")

**Returns:**
- `str`: Th√¥ng b√°o k·∫øt qu·∫£

---

### MenuController

ƒêi·ªÅu khi·ªÉn menu/giao di·ªán b·∫±ng c·ª≠ ch·ªâ.

```python
controller = MenuController()
controller.execute("one")  # Click chu·ªôt
```

**Attributes:**
- `drag_mode` (bool): Tr·∫°ng th√°i ch·∫ø ƒë·ªô k√©o

#### `execute(gesture)`
**Parameters:**
- `gesture` (str): T√™n c·ª≠ ch·ªâ

**Returns:**
- `str`: Th√¥ng b√°o k·∫øt qu·∫£

---

## GestureVisualizer

Class ƒë·ªÉ v·∫Ω giao di·ªán tr·ª±c quan.

### Constructor
```python
visualizer = GestureVisualizer()
```

### Methods

#### `draw_help_panel(frame, mode_name)`
V·∫Ω b·∫£ng h∆∞·ªõng d·∫´n b√™n tr√°i m√†n h√¨nh.

**Parameters:**
- `frame` (numpy.ndarray): Frame c·∫ßn v·∫Ω
- `mode_name` (str): T√™n ch·∫ø ƒë·ªô ("B√†n ph√≠m", "Robot", "Menu")

**Returns:**
- `numpy.ndarray`: Frame ƒë√£ v·∫Ω

#### `draw_gesture_indicator(frame, gesture, mode_name)`
V·∫Ω ch·ªâ b√°o c·ª≠ ch·ªâ hi·ªán t·∫°i.

**Parameters:**
- `frame` (numpy.ndarray): Frame c·∫ßn v·∫Ω
- `gesture` (str): T√™n c·ª≠ ch·ªâ
- `mode_name` (str): T√™n ch·∫ø ƒë·ªô

**Returns:**
- `numpy.ndarray`: Frame ƒë√£ v·∫Ω

---

## Demo Mode

### `show_demo()`
Hi·ªÉn th·ªã m√†n h√¨nh h∆∞·ªõng d·∫´n.

```python
from demo_mode import show_demo
show_demo()
```

---

## Gesture Names

### Keyboard Mode
- `"zero"` - 0 ng√≥n
- `"one"` - 1 ng√≥n
- `"two"` - 2 ng√≥n
- `"three"` - 3 ng√≥n
- `"four"` - 4 ng√≥n
- `"five"` - 5 ng√≥n

### Robot Mode
- `"forward"` - Ti·∫øn
- `"left"` - Tr√°i
- `"right"` - Ph·∫£i
- `"backward"` - L√πi
- `"stop"` - D·ª´ng

### Menu Mode
- `"one"` - Click
- `"two"` - Zoom In
- `"three"` - Zoom Out
- `"four"` - Drag
- `"five"` - Cancel

---

## Example Usage

### T√≠ch h·ª£p v√†o Project kh√°c

```python
import cv2
from gesture_detector_simple import GestureDetector

# Kh·ªüi t·∫°o
cap = cv2.VideoCapture(0)
detector = GestureDetector()

while True:
    ret, frame = cap.read()
    frame = cv2.flip(frame, 1)
    
    # Nh·∫≠n di·ªán c·ª≠ ch·ªâ
    frame, gesture = detector.process_frame(frame)
    
    # X·ª≠ l√Ω c·ª≠ ch·ªâ
    if gesture == "one":
        print("Ph√°t hi·ªán 1 ng√≥n!")
        # Th·ª±c hi·ªán h√†nh ƒë·ªông c·ªßa b·∫°n
    
    cv2.imshow("My App", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

### Custom Controller

```python
from controllers import KeyboardController

class MyCustomController(KeyboardController):
    def execute(self, gesture):
        if gesture == "one":
            # Custom action
            print("Custom action for gesture one")
            return "Custom result"
        return super().execute(gesture)
```
